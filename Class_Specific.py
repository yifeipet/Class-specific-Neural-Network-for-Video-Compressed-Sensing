# -*- coding: utf-8 -*-
"""Untitled50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XKRJlaLMXKhI3GiiPCOIuZ5nDFBSQAoi
"""

"""Author:Yifei Pei"""
# Reference Codes for Yifei Pei, Ying Liu, Nam Ling, et al., “Class-specific neural network for video compressed sensing”, in 54th IEEE International Symposium on Circuits and Systems (ISCAS 2021), Daegu, Korea.
!pip install pandas
!pip install PyWavelets
!pip install keras
!pip install scipy
!pip install sklearn

from zipfile import ZipFile
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import load_model
import glob
import numpy as np
import pandas as pd
import random
import scipy.fftpack
import pywt
from sklearn.mixture import GaussianMixture

folders = glob.glob('container/*')
folders.sort()
print(folders)

random.seed(4)

random.shuffle(folders)

training_set = []
testing_set = []

w, h = 352, 288
px = w*h

Y_list = []

for i in range(300):
    YUV = np.fromfile(folders[i],dtype = 'uint8')
    Y = YUV[0:w*h].reshape(h,w)
    Y_list.append(Y)

for i in range(300):
    if i < 210:
        training_set.append(Y_list[i])
    else:
        testing_set.append(Y_list[i])

training_block = []
testing_block = []

for i in range(210):
    img = training_set[i]
    for x in range(0, img.shape[0],16):
        for y in range(0, img.shape[1],16):
            training_block.append(img[x:x+16, y:y+16])
    

for i in range(90):
    img = testing_set[i]
    for x in range(0, img.shape[0],16):
        for y in range(0, img.shape[1],16):
            testing_block.append(img[x:x+16, y:y+16])

print(len(training_block))
print(len(testing_block))

(cA, cD) = pywt.dwt(np.eye(16), 'db1')

x = np.concatenate((cA, cD), axis=1)

def dwt2(array):
    return np.dot(np.dot(x, array), x.T)

def idwt2(array):
    return np.dot(np.dot(x.T, array), x)

vec_training_block_DWT = []
vec_testing_block_DWT = []

for i in range(83160):
    vec_training_block_DWT.append((dwt2(training_block[i])).reshape((256,)))           # Vectorize all training blocks

for i in range(35640):
    vec_testing_block_DWT.append((dwt2(testing_block[i])).reshape((256,)))              # Vectorize all testing blocks

def dct2(a):
    return scipy.fftpack.dct( scipy.fftpack.dct( a, axis=0, norm='ortho' ), axis=1, norm='ortho' )

def idct2(a):
    return scipy.fftpack.idct( scipy.fftpack.idct( a, axis=0 , norm='ortho'), axis=1 , norm='ortho')

vec_training_block_DCT = []
vec_testing_block_DCT = []

for i in range(83160):
    vec_training_block_DCT.append((dct2(training_block[i])).reshape((256,)))           # Vectorize all training blocks

for i in range(35640):
    vec_testing_block_DCT.append((dct2(testing_block[i])).reshape((256,)))              # Vectorize all testing blocks

vec_training_block = []
vec_testing_block = []

for i in range(83160):
    vec_training_block.append(training_block[i].reshape((256,)))           # Vectorize all training blocks

for i in range(35640):
    vec_testing_block.append(testing_block[i].reshape((256,)))              # Vectorize all testing blocks

'''Create Dummy Arrays to Save Train and Test Set for Pixels'''
X_train = numpy.random.randn(83160,256)
X_test = numpy.random.randn(35640,256)

'''Create Dummy Arrays to Save Train and Test Set for DCT Frequencies'''
X_train_DCT = numpy.random.randn(83160,256)
X_test_DCT = numpy.random.randn(35640,256)

'''Create Dummy Arrays to Save Train and Test Set for DWT Frequencies'''
X_train_DWT = numpy.random.randn(83160,256)
X_test_DWT = numpy.random.randn(35640,256)

for i in range(83160):
    X_train_DCT[i,:] = vec_training_block_DCT[i]          # All vectorized training blocks are saved in X_train
    
for i in range(35640):
    X_test_DCT[i,:] = vec_testing_block_DCT[i]          # All vectorized testing blocks are saved in X_test

for i in range(83160):
    X_train[i,:] = vec_training_block[i]          # All vectorized training blocks are saved in X_train
    
for i in range(35640):
    X_test[i,:] = vec_testing_block[i]          # All vectorized testing blocks are saved in X_test

for i in range(83160):
    X_train_DWT[i,:] = vec_training_block_DWT[i]          # All vectorized training blocks are saved in X_train
    
for i in range(35640):
    X_test_DWT[i,:] = vec_testing_block_DWT[i]          # All vectorized testing blocks are saved in X_test

def ANN(R, X_train, X_test):
    encoding_dim = int(R*256)  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats
    
    input_img = Input(shape=(256,), name='encoder_input')
    
    x = input_img
    
    x = Dense(128, activation = None, bias = True)(x)
    
    latent = Dense(encoding_dim, name='latent_vector', activation = None, bias = True)(x)
    
    encoder = Model(input_img, latent, name='encoder')
    
    encoder.summary()
    
    latent_inputs = Input(shape=(encoding_dim,), name='decoder_input')
    
    reconstruction = Dense(256*12, activation = 'relu')(latent_inputs)
    
    outputs = Dense(256)(reconstruction)

    
    decoder = Model(latent_inputs, outputs, name='decoder')
    
    decoder.summary()
    
    autoencoder = Model(input_img, decoder(encoder(input_img)), name='autoencoder')
    
    autoencoder.summary()
    
    autoencoder.compile(loss='mse', optimizer='adam')
    
    history = autoencoder.fit(X_train, X_train,
                epochs=150,
                batch_size=64,
                shuffle=True,
                validation_data=(X_test, X_test))
    return autoencoder, encoder, decoder, history

'''Train the neural network based on pixel features'''
autoencoder010, encoder010, decoder010, history010 = ANN(0.10, X_train, X_test)

'''Train the neural network based on DCT frequencies'''
autoencoder010_DCT, encoder010_DCT, decoder010_DCT, history010_DCT = ANN(0.10, X_train_DCT, X_test_DCT)

'''Train the neural network based on DWT frequencies'''
autoencoder010_DWT, encoder010_DWT, decoder010_DWT, history010_DWT = ANN(0.10, X_train_DWT, X_test_DWT)

'''Train a Gaussian Mixture model (n=3)'''
gm3_DCT = GaussianMixture(n_components=3, n_init= 5, covariance_type='full', verbose = 1,warm_start=True)
gm3_DCT.fit(Train_set_DCT)

'''Calculate AIC and BIC information. It can help us to select the number of cluster'''
print(gm3_DCT.bic(Train_set_DCT))
print(gm3_DCT.aic(Train_set_DCT))

'''Use the trained Gaussian mixture model to predict the labels of video blocks'''
X_train_DCT_label = gm3_DCT.predict(X_train_DCT)
X_validation_DCT_label = gm3_DCT.predict(X_validation_DCT)
X_test_DCT_label = gm3_DCT.predict(X_test_DCT)

'''Reshape the label vectors.'''
X_train_DCT_label = X_train_DCT_label.reshape(225750,1)
X_validation_DCT_label = X_validation_DCT_label.reshape(90300,1)
X_test_DCT_label = X_test_DCT_label.reshape(35640,1)

'''Labels are concatenated to images'''
X_train_DCT_labeled = np.concatenate((X_train_DCT, X_train_DCT_label), axis = 1)
X_validation_DCT_labeled = np.concatenate((X_validation_DCT, X_validation_DCT_label), axis = 1)
X_test_DCT_labeled = np.concatenate((X_test_DCT, X_test_DCT_label), axis = 1)

'''Prepare for training three networks'''
X_train_DCT_labeled0 = X_train_DCT_labeled[X_train_DCT_labeled[:,-1]==0]
X_validation_DCT_labeled0 = X_validation_DCT_labeled[X_validation_DCT_labeled[:,-1]==0]
X_test_DCT_labeled0 = X_test_DCT_labeled[X_test_DCT_labeled[:,-1]==0]

X_train_DCT_labeled1 = X_train_DCT_labeled[X_train_DCT_labeled[:,-1]==1]
X_validation_DCT_labeled1 = X_validation_DCT_labeled[X_validation_DCT_labeled[:,-1]==1]
X_test_DCT_labeled1 = X_test_DCT_labeled[X_test_DCT_labeled[:,-1]==1]

X_train_DCT_labeled2 = X_train_DCT_labeled[X_train_DCT_labeled[:,-1]==2]
X_validation_DCT_labeled2 = X_validation_DCT_labeled[X_validation_DCT_labeled[:,-1]==2]
X_test_DCT_labeled2 = X_test_DCT_labeled[X_test_DCT_labeled[:,-1]==2]

autoencoder0_3_10_DCT, encoder0_3_10_DCT, decoder0_3_10_DCT, history0_3_10_DCT = ANN(0.1, X_train_DCT_labeled0[:,:-1], X_validation_DCT_labeled0[:,:-1])

autoencoder1_3_10_DCT, encoder1_3_10_DCT, decoder1_3_10_DCT, history1_3_10_DCT = ANN(0.1, X_train_DCT_labeled1[:,:-1], X_validation_DCT_labeled1[:,:-1])

autoencoder2_3_10_DCT, encoder2_3_10_DCT, decoder2_3_10_DCT, history2_3_10_DCT = ANN(0.1, X_train_DCT_labeled2[:,:-1], X_validation_DCT_labeled2[:,:-1])

def classifier_accuracy_3_DCT(encoder0_3, encoder1_3, encoder2_3):
  y_train_labeled0_3 = np.concatenate((encoder0_3.predict(X_train_DCT_labeled0_3[:,:-1]),X_train_DCT_label0_3),axis=1)
  y_test_labeled0_3 = np.concatenate((encoder0_3.predict(X_test_DCT_labeled0_3[:,:-1]),X_test_DCT_label0_3),axis =1)
  y_train_labeled1_3 = np.concatenate((encoder1_3.predict(X_train_DCT_labeled1_3[:,:-1]),X_train_DCT_label1_3),axis=1)
  y_test_labeled1_3 = np.concatenate((encoder1_3.predict(X_test_DCT_labeled1_3[:,:-1]),X_test_DCT_label1_3),axis =1)
  y_train_labeled2_3 = np.concatenate((encoder2_3.predict(X_train_DCT_labeled2_3[:,:-1]),X_train_DCT_label2_3),axis=1)
  y_test_labeled2_3 = np.concatenate((encoder2_3.predict(X_test_DCT_labeled2_3[:,:-1]),X_test_DCT_label2_3),axis =1)
  data = np.concatenate((y_train_labeled0_3, y_train_labeled1_3),axis = 0)
  data = np.concatenate((data, y_train_labeled2_3),axis = 0)
  data_test = np.concatenate((y_test_labeled0_3, y_test_labeled1_3),axis =0)
  data_test = np.concatenate((data_test, y_test_labeled2_3),axis = 0)
  clf = LogisticRegression(random_state=0, verbose=1, max_iter=2000).fit(data[:,:-1], data[:,-1])
  return clf.score(data[:,:-1], data[:,-1]), clf.score(data_test[:,:-1],data_test[:,-1])

"""Accuracies of prediction by the trained logistic regression for compressed blocks are 1 for train set and test set.
The accuracies are only decreased to 0.9997 when the number of clusters is 6 and the sensing rate is 0.05, which indicates we can use a logistic classifier to predict the labels of compressive sensed blocks"""
classifier_accuracy_3_DCT(encoder0_3_10_DCT,encoder1_3_10_DCT, encoder2_3_10_DCT)